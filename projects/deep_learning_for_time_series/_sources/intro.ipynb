{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60898c4f",
   "metadata": {},
   "source": [
    "# Demand forecasting: Deep learning vs. time series models\n",
    "\n",
    "## Highlights\n",
    "\n",
    "* 2 sales datasets are used for the comparison of state of the art deep learning models and linear time series models.\n",
    "* Unexpectedly, ARIMA and ETS outperform the deep learning models for long time series and vice versa for short time series.\n",
    "* The results are generated without hyperparameter tuning of the DL models but they indicate that simple models can be competitive. \n",
    "\n",
    "## Datasets\n",
    "\n",
    "There are 2 datasets used as summarized in the table below: \n",
    "\n",
    "\n",
    "```{table} Datasets used in this comparison\n",
    ":name: my-table-ref\n",
    "|Dataset number | Dataset name | Type | Reference | Frequency | # Time Series | # Time series periods |\n",
    "|---|---|---|---|---|---|---|\n",
    "|1| Stallion (Kaggle) | Artificial |  [Source]( https://www.kaggle.com/utathya/future-volume-prediction)  | Month | 350 | 60 | \n",
    "|2| Walmart (M5 competition) | Real |  [Source](https://www.kaggle.com/c/m5-forecasting-accuracy/data) | Day | 1000 |  ~1910 |\n",
    "```\n",
    "\n",
    "All 350 time series in the Stallion dataset are used. The data is part of the pytorch forecasting module. \n",
    "\n",
    "The second dataset is the M5 competition data that originally contains more than 32k time series on the lowest of twelve hierarchies that were required to be forecasted.  It has to be downloaded from the [Kaggle](https://www.kaggle.com/c/m5-forecasting-accuracy/data) website. Only a random sample of 1,000 time series is used for fhe analysis here in order to limit the computation time.\n",
    "\n",
    "\n",
    "\n",
    "## Models\n",
    "\n",
    "There are three univariate time series models and two deep learning models used in the comparison. The Theta model won the M3 time series competition. \n",
    "\n",
    "AutoArima and AutoETS are not applied to the M5 competition data (dataset 2) because the runtime was too long. Theta is by far faster. \n",
    "\n",
    "```{table} Models used in this comparison\n",
    ":name: my-table-ref\n",
    "\n",
    "| Model name | Type | Reference | Covariates | Applied to Dataset 1|Applied to Dataset 2|\n",
    "|---|---|---|---|---|---|\n",
    "| Seasonal Naive | Univariate time series |    | No|Yes|Yes|\n",
    "| Theta | Univariate time series |   {cite:p}`Assimakopoulos2000`  | No|Yes|Yes|\n",
    "| AutoArima | Univariate time series |  |No|Yes|No|\n",
    "| AutoETS | Univariate time series |  |No|Yes|No|\n",
    "| Nbeats | Deep neural network | {cite:p}`oreshkin2020nbeats` |No|Yes|Yes|\n",
    "| Temporal Fusion Transformer | Deep neural network | {cite:p}`lim2020temporal` | Yes |Yes|Yes|\n",
    "```\n",
    "\n",
    "## References\n",
    "\n",
    "```{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.8",
    "jupytext_version": "1.4.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "source_map": [
   12
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}